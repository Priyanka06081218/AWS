{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nJZGw2AxoK7u"
   },
   "outputs": [],
   "source": [
    "pip install opendatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TWp6qL7Onuwf",
    "outputId": "bd10b6d0-5c96-4155-b5f7-77278e9e462c"
   },
   "outputs": [],
   "source": [
    "project_name = 'hand-bag-new'\n",
    "!pip install opendatasets --upgrade \n",
    "import opendatasets as od\n",
    "od.download('https://www.kaggle.com/bashturtle/shirtshandbags')\n",
    "import os\n",
    "data_dir='./shirtshandbags'\n",
    "print(os.listdir(data_dir))\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as T\n",
    "import torch\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4-tFTAVsosJZ"
   },
   "outputs": [],
   "source": [
    "im_sz = 64\n",
    "batch_sz = 128\n",
    "new_stats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\n",
    "train1 = ImageFolder(data_dir, transform=T.Compose([\n",
    "T.Resize(im_sz), T.CenterCrop(im_sz), T.ToTensor(), T.Normalize(*new_stats)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p4XRsDcfo7nw",
    "outputId": "b7785449-3b3d-43e2-dc6c-012f83f20d53"
   },
   "outputs": [],
   "source": [
    "train2 = DataLoader(train1, batch_sz, shuffle=True, num_workers=3, pin_memory=True)\n",
    "def denormalize(im_tensors):\n",
    "  return im_tensors * new_stats[1][0] + new_stats[0][0] \n",
    "def show_img(images, nmax=64):\n",
    "  fig, ax = plt.subplots(figsize=(8, 8))\n",
    "  ax.set_xticks([]); ax.set_yticks([])\n",
    "  ax.imshow(make_grid(denormalize(images.detach()[:nmax]), nrow=8).permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "id": "3-TTe1mZpKbQ",
    "outputId": "81180e4c-6ad5-4c1a-cc5f-4f47fb884930"
   },
   "outputs": [],
   "source": [
    "def show_batch(dl, nmax=64):\n",
    "  for images, _ in dl:\n",
    "    show_img(images, nmax)\n",
    "    break \n",
    "show_batch(train2)\n",
    "def get_device():\n",
    "  if torch.cuda.is_available():\n",
    "    return torch.device('cuda')\n",
    "  else:\n",
    "    return torch.device('cpu')\n",
    "def to_device(data, device):\n",
    "  if isinstance(data, (list,tuple)):\n",
    "    return [to_device(x, device) for x in data] \n",
    "  return data.to(device, non_blocking=True)\n",
    "class DeviceDataLoader():\n",
    "  def __init__(self, dl, device):\n",
    "    self.dl = dl \n",
    "    self.device = device\n",
    "  def __iter__(self): \n",
    "    for b in self.dl:\n",
    "      yield to_device(b, self.device)\n",
    "  def __len__(self): \n",
    "    return len(self.dl)\n",
    "device=get_device()\n",
    "train2 = DeviceDataLoader(train2, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o66z49BiqSdm"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "discriminator = nn.Sequential(\n",
    "nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1, bias=False), # in: 3 x 64 x 64 nn.BatchNorm2d(64),\n",
    "nn.LeakyReLU(0.2, inplace=True),\n",
    "nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False), # out: 64 x 32 x 32 nn.BatchNorm2d(128),\n",
    "nn.LeakyReLU(0.2, inplace=True),\n",
    "nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False), nn.BatchNorm2d(256),# out: 128 x 16 x 16\n",
    "nn.LeakyReLU(0.2, inplace=True),\n",
    "nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=False), nn.BatchNorm2d(512),# out: 256 x 8 x 8\n",
    "nn.LeakyReLU(0.2, inplace=True),\n",
    "nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0, bias=False), # out: 512 x 4 x 4\n",
    "nn.Flatten(), # out: 1 x 1 x 1\n",
    "nn.Sigmoid())\n",
    "discriminator = to_device(discriminator, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "A_eU3S2yquzz",
    "outputId": "6e9f3c93-e105-4961-e64c-cd6e165214bc"
   },
   "outputs": [],
   "source": [
    "latent_size=128\n",
    "#generator network\n",
    "generator = nn.Sequential(\n",
    "# in: latent_size x 1 x 1\n",
    "nn.ConvTranspose2d(latent_size, 512, kernel_size=4, stride=1, padding=0, bias=False), # out: 512 x 4 x 4\n",
    "nn.BatchNorm2d(512), nn.ReLU(True),\n",
    "nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False),#out: 256x8x8\n",
    "nn.BatchNorm2d(256), nn.ReLU(True),\n",
    "nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),#out:128x 16 x 16\n",
    "nn.BatchNorm2d(128), nn.ReLU(True),\n",
    "nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False),#out:64 32 x 32\n",
    "nn.BatchNorm2d(64), nn.ReLU(True),\n",
    "nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1, bias=False),#out:3 x 64 x 64\n",
    "nn.Tanh()\n",
    ")\n",
    "xb = torch.randn(batch_sz, latent_size, 1, 1) # random latent tensors \n",
    "fake_images = generator(xb)\n",
    "print(fake_images.shape)\n",
    "show_img(fake_images)\n",
    "generator = to_device(generator, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DJgIsmMHsWTV"
   },
   "outputs": [],
   "source": [
    "def train_discriminator(real_images, opt_d):\n",
    "  opt_d.zero_grad()\n",
    "  real_preds = discriminator(real_images)\n",
    "  real_targets = torch.ones(real_images.size(0), 1, device=device)\n",
    "  real_loss = F.binary_cross_entropy(real_preds, real_targets) \n",
    "  real_score = torch.mean(real_preds).item()\n",
    "  latent = torch.randn(batch_sz, latent_size, 1, 1, device=device) \n",
    "  fake_images = generator(latent)\n",
    "  fake_targets = torch.zeros(fake_images.size(0), 1, device=device) \n",
    "  fake_preds = discriminator(fake_images)\n",
    "  fake_loss = F.binary_cross_entropy(fake_preds, fake_targets) \n",
    "  fake_score = torch.mean(fake_preds).item()\n",
    "  loss = real_loss + fake_loss \n",
    "  loss.backward()\n",
    "  opt_d.step()\n",
    "  return loss.item(), real_score, fake_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n5VL9QBjsu9o"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "def train_generator(opt_g):\n",
    "  opt_g.zero_grad()\n",
    "  latent = torch.randn(batch_sz, latent_size, 1, 1, device=device)\n",
    "  fake_images = generator(latent)\n",
    "  preds = discriminator(fake_images)\n",
    "  targets = torch.ones(batch_sz, 1, device=device)\n",
    "  loss = F.binary_cross_entropy(preds, targets)\n",
    "  loss.backward()\n",
    "  opt_g.step()\n",
    "  return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505
    },
    "id": "hEbuKwGCtCQ6",
    "outputId": "7ce5f561-0656-4b23-f181-4cdd21262f62"
   },
   "outputs": [],
   "source": [
    "from torchvision.utils import save_image\n",
    "sample_dir = 'generated'\n",
    "os.makedirs(sample_dir, exist_ok=True)\n",
    "def save_samples(index, latent_tensors, show=True):\n",
    "  fake_images = generator(latent_tensors)\n",
    "  fake_fname = 'generated-images-{0:0=4d}.png'.format(index) \n",
    "  save_image(denormalize(fake_images), os.path.join(sample_dir, fake_fname), nrow=8) \n",
    "  print('Saving', fake_fname)\n",
    "  if show:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.set_xticks([]); ax.set_yticks([]) \n",
    "    ax.imshow(make_grid(fake_images.cpu().detach(), nrow=8).permute(1, 2, 0))\n",
    "fixed_latent = torch.randn(64, latent_size, 1, 1, device=device) \n",
    "save_samples(0, fixed_latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p8OKAiYNth1c"
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "def fit(epochs, lr, start_idx=1): \n",
    "  torch.cuda.empty_cache()\n",
    "  losses_g = [] \n",
    "  losses_d = [] \n",
    "  real_scores = [] \n",
    "  fake_scores = []\n",
    "  opt_d = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999)) \n",
    "  opt_g = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "  for epoch in range(epochs):\n",
    "    for real_images, _ in tqdm(train2):\n",
    "      loss_d, real_score, fake_score = train_discriminator(real_images, opt_d) # Train generator\n",
    "      loss_g = train_generator(opt_g) \n",
    "    losses_g.append(loss_g) \n",
    "    losses_d.append(loss_d) \n",
    "    real_scores.append(real_score) \n",
    "    fake_scores.append(fake_score)\n",
    "    print(\"Epoch [{}/{}], loss_g: {:.4f}, loss_d: {:.4f}, real_score: {:.4f}, fake_score: {:.4f}\".format(epoch+1, epochs, loss_g, loss_d, real_score, fake_score))\n",
    "    save_samples(epoch+start_idx, fixed_latent, show=False)\n",
    "  return losses_g, losses_d, real_scores, fake_scores  \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 886,
     "referenced_widgets": [
      "fda5fe1f6b2042dc85a4eb923e13d1bb",
      "8532463f219545b8b8dd0d2a271cb2c2",
      "753873d07a9943dab6c990b8febaa172",
      "81eab0cf21c248eca85d8eea5a691485",
      "2b8950f49bf446c0895d7e39c43146df",
      "f077a2c116b7446fa1f2368adf5cf9d9",
      "980a8a25093b477fae7fa587e3160636",
      "f2040dc58f594d868375db7d52c0abf0",
      "bd930a20227f4b87af8bb18d8a9b592f",
      "24cf55c6f4cc41b0996487a82148483c",
      "1312ec7ebee54509b2c15284f6b88d05",
      "6ac7dc6dde5943f585ca0fc65b41af67",
      "bbf687bd81d94335a9ed01a921d61eda",
      "5ad75da48b164373b0bf7f2ba6a334e0",
      "3afeec9c2e0342a09421acfc545476b1",
      "e3fb0c054fba4ecaa51fbe3ead5b0f4d",
      "7dbbd66b443b4039909ee88887153fdc",
      "3cb0ec220e6b40f6822e5311c8c40e5f",
      "7b602bdf3ca542b8a53164a4913b3853",
      "28b79c403b42460a809a3e572d1f22c5",
      "077418abaec44a318c4c67ddbc1184cf",
      "04c62480c9d34231acf4bdfd349f8b97",
      "95d66c21495345ae94cb6b73f136f4e8",
      "304fc026e0144881b674870c4afb327a",
      "b5ed473e640e45be82aabf45ee093c48",
      "d71fbff70cdd490aaacc59221b6992cb",
      "833832e1678947639a4d7d5b920de25d",
      "38468be07d6f45259df7f9ed33a69197",
      "2183d1dc0fc34d0fb62abaf501dcea71",
      "be33fd0ee28a4163a58a5dd26ecb748a",
      "eaae66b998c14964a1d06a93d5293ecb",
      "473e85a955f349f1b545c259211ff611",
      "78681f4740c4405fbcb42dc93bb9aff0",
      "d2594c9bb3b1403ba9464a1ac9dfd04d",
      "edf6fc4710ed436c90261c8a971e68df",
      "2912b11d1b154cc981d58b7851519314",
      "7d9f881e28a24506962274d987b3088a",
      "ba8c66c78d7948f69bba233f1b99be5a",
      "f1739468920642c3a937d698b2c3cbce",
      "4c33631eafb04f0e92f5f76c85e84b78",
      "655e91e9d8d6404bb90f22c83ea90a76",
      "a168020ce7434301877e2e30138f01e1",
      "70399e3cc18147c58c2ffb5c409d2b62",
      "1c9ac10db8df4506b6364898c8457852",
      "7f46355114fd4e7082bbdd3e033ab739",
      "c1f5d38238194c1ea6e1e386d7b27b8a",
      "dc7b75e57ea44fd7b2e3f691d2f8fb5e",
      "6c4033eba64a4749ab9e8ceca93248d8",
      "00d3f5049bdb4ba6a64a987c72eebeb5",
      "5ea5acad74024d30ba214a7f72222aee",
      "a1e77b2298204c85be226ca620b76081",
      "4403ccdd5ce1408fa2abc3710b02504b",
      "c51d200c71c44d128a7ca0d2c3ad5cd5",
      "b25cdcc0023542578e6db6e6718ad4ea",
      "391c74dcc82e42278d6c3e19709ccf26"
     ]
    },
    "id": "nrbF8h8CugaU",
    "outputId": "3c839399-1c17-4899-cd9b-dc109c35550f"
   },
   "outputs": [],
   "source": [
    "lr = 0.0003\n",
    "epochs =5\n",
    "history = fit(epochs, lr)\n",
    "losses_g, losses_d, real_scores, fake_scores = history \n",
    "torch.save(generator.state_dict(), 'G.pth') \n",
    "torch.save(discriminator.state_dict(), 'D.pth')\n",
    "from IPython.display import Image \n",
    "Image('./generated/generated-images-0001.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547
    },
    "id": "TFe3ZCHBxGJ1",
    "outputId": "19df182a-099d-432f-c090-b0fe1a957dba"
   },
   "outputs": [],
   "source": [
    "Image('./generated/generated-images-0004.png')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
